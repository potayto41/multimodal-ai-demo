# ğŸ“¸ Gemini Multimodal Image Description App

A simple, lightweight Python application that uses **Google Gemini 2.5 Flash** to:
- ğŸ–¼ï¸ Upload images  
- ğŸ¤– Generate detailed AI descriptions  
- ğŸ“ Provide clean text outputs  
- ğŸŒ Interact through a Streamlit-based UI  

This project demonstrates how to integrate **Gemini's multimodal capabilities** with a user-friendly interface.

---

## ğŸš€ Features
### **1. Image Description**
Upload any JPG/PNG image and receive an AIâ€‘generated detailed description.

### **2. Gemini API Integration**
Uses:
```python
from google import genai

ğŸ“¦ Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
2ï¸âƒ£ Install dependencies
pip install -r requirements.txt
3ï¸âƒ£ Set your API key
Create a file named GEMINI_API_KEY.env (already included in repo) or export environment variable:

export GEMINI_API_KEY="your_api_key"
4ï¸âƒ£ Run the app
streamlit run app.py

ğŸ“‚ project
â”‚â”€â”€ app.py                 # Streamlit UI
â”‚â”€â”€ multimodal_test.py     # Backend multimodal test
â”‚â”€â”€ test.py                # Simple "Say hello" test
â”‚â”€â”€ test_image.jpg         # Sample image
â”‚â”€â”€ test_image2.jpg        # Sample image
â”‚â”€â”€ GEMINI_API_KEY.env     # API key file (not pushed to GitHub)
â”‚â”€â”€ .gitignore             # Ignoring secrets/files
â”‚â”€â”€ README.md              # This file
GEMINI_API_KEY=your_key_here

